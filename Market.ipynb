{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "q1sDq83ryJXp"
      },
      "outputs": [],
      "source": [
        "# Step 1: 导入库\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1.1: 定义 RSI 函数\n",
        "def compute_rsi(series, period=14):\n",
        "    delta = series.diff()\n",
        "    gain = delta.clip(lower=0).rolling(window=period).mean()\n",
        "    loss = -delta.clip(upper=0).rolling(window=period).mean()\n",
        "    rs = gain / (loss + 1e-10)  # 防止除以0\n",
        "    rsi = 100 - (100 / (1 + rs))\n",
        "    return rsi\n"
      ],
      "metadata": {
        "id": "E0T9Y6jUyplE"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: 读取数据\n",
        "df = pd.read_csv('/content/Nasdaq100Data.csv', parse_dates=['Date'])\n",
        "\n",
        "# Step 2.1: 转换数字格式\n",
        "for col in ['Price', 'Open', 'High', 'Low']:\n",
        "    df[col] = df[col].astype(str).str.replace(',', '').astype(float)\n",
        "\n",
        "# Step 2.2: 添加技术指标\n",
        "df['MA10'] = df['Price'].rolling(10).mean()\n",
        "df['RSI'] = compute_rsi(df['Price'])\n",
        "# === 添加增强特征 ===\n",
        "df['Return5'] = df['Price'].pct_change(5)\n",
        "df['Volatility5'] = df['Price'].rolling(5).std()\n",
        "df['Bias_MA10'] = (df['Price'] - df['MA10']) / df['MA10']\n",
        "\n",
        "# 最后更新你的特征列\n",
        "feature_cols = ['Price', 'MA10', 'RSI', 'Return5', 'Volatility5', 'Bias_MA10']\n",
        "\n",
        "\n",
        "# Step 2.3: 删除NaN\n",
        "df.dropna(inplace=True)\n",
        "df.reset_index(drop=True, inplace=True)\n"
      ],
      "metadata": {
        "id": "JcTvlJpvyKx9"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 确保按时间升序排列并重置索引\n",
        "df = df.sort_values('Date').reset_index(drop=True)\n",
        "\n",
        "# 标签构造：严格比较今天与未来5天每一天的价格\n",
        "labels = []\n",
        "for i in range(len(df) - 5):\n",
        "    current = df.loc[i, 'Price']\n",
        "    future = df.loc[i+1:i+5, 'Price'].values\n",
        "\n",
        "    if np.all(current < future):\n",
        "        labels.append(1)  # 当前比未来都低 → 最低点（买入）\n",
        "    elif np.all(current > future):\n",
        "        labels.append(2)  # 当前比未来都高 → 最高点（卖出）\n",
        "    else:\n",
        "        labels.append(0)  # 中间区域，不确定\n",
        "\n",
        "# 尾部补0（未来不足5天无法判断）\n",
        "labels += [0] * (len(df) - len(labels))\n",
        "\n",
        "df['label'] = labels\n"
      ],
      "metadata": {
        "id": "gD5Yma60yK2p"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 统计标签分布\n",
        "unique, counts = np.unique(df['label'], return_counts=True)\n",
        "label_count = dict(zip(unique, counts))\n",
        "\n",
        "# 显示结果\n",
        "print(\"\\n=== 标签分布统计 ===\")\n",
        "print(f\"不确定（label=0）：{label_count.get(0, 0)} 天\")\n",
        "print(f\"最低点（label=1，高点信号）：{label_count.get(1, 0)} 天\")\n",
        "print(f\"最高点（label=2，低点信号）：{label_count.get(2, 0)} 天\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZDSmu1nW0dHX",
        "outputId": "1098ab82-f87d-4334-ccc6-45ba570cf002"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== 标签分布统计 ===\n",
            "不确定（label=0）：1175 天\n",
            "最低点（label=1，高点信号）：699 天\n",
            "最高点（label=2，低点信号）：381 天\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.loc[df['label'] == 1].tail(10))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f9yXh4cm2N8_",
        "outputId": "e07ff1c5-f54e-4c44-bf77-dac4e4d01571"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "           Date     Price      Open      High       Low     Vol. Change %  \\\n",
            "2191 2025-01-27  21127.28  21000.17  21292.54  20974.90  631.40M   -2.97%   \n",
            "2196 2025-02-03  21297.58  21084.64  21406.58  21004.35  387.17M   -0.84%   \n",
            "2200 2025-02-07  21491.31  21776.28  21869.32  21465.46  323.70M   -1.30%   \n",
            "2202 2025-02-11  21693.52  21629.11  21776.25  21625.51  283.61M   -0.29%   \n",
            "2203 2025-02-12  21719.26  21475.41  21745.66  21454.19  308.36M    0.12%   \n",
            "2223 2025-03-13  19225.48  19534.37  19558.56  19152.57  398.60M   -1.89%   \n",
            "2226 2025-03-18  19483.36  19657.10  19676.05  19397.07  333.56M   -1.66%   \n",
            "2228 2025-03-20  19677.61  19558.28  19888.85  19549.31  371.49M   -0.30%   \n",
            "2241 2025-04-08  17090.40  18034.46  18207.01  16850.18  660.31M   -1.95%   \n",
            "2249 2025-04-21  17808.30  18023.01  18043.08  17592.92  347.85M   -2.46%   \n",
            "\n",
            "           MA10        RSI   Return5  Volatility5  Bias_MA10  label  \n",
            "2191  21477.598  27.595220 -0.007996   155.108243  -0.016311      1  \n",
            "2196  21710.294  48.861481 -0.021104   179.623824  -0.019010      1  \n",
            "2200  21882.857  60.609472 -0.028189   193.141854  -0.017893      1  \n",
            "2202  21801.985  71.887068 -0.021739   222.805528  -0.004975      1  \n",
            "2203  21745.925  66.459341 -0.015806   188.712292  -0.001226      1  \n",
            "2223  19777.922  44.346060 -0.022977   238.879664  -0.027932      1  \n",
            "2226  19739.534  73.051699 -0.039653   255.182131  -0.012978      1  \n",
            "2228  19719.352  54.074642 -0.006112   264.601710  -0.002117      1  \n",
            "2241  18349.577  29.922965 -0.092396   792.695425  -0.068622      1  \n",
            "2249  19185.751  11.023965 -0.083336   666.094441  -0.071796      1  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jNPjABkB2V4J"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import numpy as np\n",
        "\n",
        "# 替换 inf 为 NaN（这一步必须放前面）\n",
        "df[feature_cols] = df[feature_cols].replace([np.inf, -np.inf], np.nan)\n",
        "\n",
        "# 记录被删除的行\n",
        "na_mask = df[feature_cols].isna()\n",
        "rows_with_na = df[na_mask.any(axis=1)].copy()\n",
        "\n",
        "print(f\"\\n🧹 删除含无效特征的行数：{len(rows_with_na)} 行\")\n",
        "\n",
        "# 输出被删除行的关键信息（日期、价格、缺失项）\n",
        "for idx, row in rows_with_na.iterrows():\n",
        "    na_cols = na_mask.loc[idx]\n",
        "    missing_features = [col for col, is_na in na_cols.items() if is_na]\n",
        "    date = row['Date']\n",
        "    price = row['Price']\n",
        "    print(f\"📉 日期: {date.date()} | 价格: {price:.2f} | 缺失特征: {', '.join(missing_features)}\")\n",
        "\n",
        "# 执行删除并重置索引\n",
        "df = df.dropna(subset=feature_cols).reset_index(drop=True)\n",
        "\n",
        "# 标准化特征\n",
        "scaler = MinMaxScaler()\n",
        "df[feature_cols] = scaler.fit_transform(df[feature_cols])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l0JUHVc9zhWv",
        "outputId": "75c36eb7-abe2-4fe8-f9a7-2bcdf9fca7b0"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🧹 删除含无效特征的行数：0 行\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X, y, indices = [], [], []\n",
        "\n",
        "for i in range(30, len(df)):\n",
        "    seq = df.loc[i-30:i-1, feature_cols].values\n",
        "    label = df.loc[i, 'label']\n",
        "\n",
        "    if not np.isfinite(seq).all():\n",
        "        continue\n",
        "    if seq.shape != (30, len(feature_cols)):\n",
        "        continue\n",
        "\n",
        "    X.append(seq)\n",
        "    y.append(label)\n",
        "    indices.append(i)  # 记录当前样本标签所在的日期索引，用于预测展示\n",
        "\n",
        "X = np.array(X, dtype=np.float32)\n",
        "y = np.array(y, dtype=np.int32)\n"
      ],
      "metadata": {
        "id": "sPsLLHqJ4K3Y"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"\\n✅ 最终训练样本数：{X.shape[0]}, 输入维度：{X.shape[1:]}\")\n",
        "\n",
        "# 标签统计\n",
        "unique, counts = np.unique(y, return_counts=True)\n",
        "print(\"\\n📊 标签分布：\")\n",
        "for u, c in zip(unique, counts):\n",
        "    name = {0: \"观望\", 1: \"买入\", 2: \"卖出\"}.get(u, \"未知\")\n",
        "    print(f\"Label {u}（{name}）→ {c} 条\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g_nxZqRU6A-2",
        "outputId": "838eb59d-8fbb-44de-a4a4-64284c9f9196"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ 最终训练样本数：2225, 输入维度：(30, 6)\n",
            "\n",
            "📊 标签分布：\n",
            "Label 0（观望）→ 1158 条\n",
            "Label 1（买入）→ 694 条\n",
            "Label 2（卖出）→ 373 条\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import numpy as np\n",
        "\n",
        "# === 设置你要用的特征列（这些列必须已存在） ===\n",
        "feature_cols = ['Price', 'MA10', 'RSI', 'Return5', 'Volatility5', 'Bias_MA10']\n",
        "\n",
        "# === 标准化特征列 ===\n",
        "scaler = MinMaxScaler()\n",
        "df[feature_cols] = scaler.fit_transform(df[feature_cols])\n",
        "\n",
        "# === 构造样本序列 X 和标签 y ===\n",
        "X, y, indices = [], [], []\n",
        "\n",
        "for i in range(30, len(df)):\n",
        "    seq = df.loc[i-30:i-1, feature_cols].values\n",
        "    label = df.loc[i, 'label']\n",
        "\n",
        "    if not np.isfinite(seq).all():\n",
        "        continue\n",
        "    if seq.shape != (30, len(feature_cols)):\n",
        "        continue\n",
        "\n",
        "    X.append(seq)\n",
        "    y.append(label)\n",
        "    indices.append(i)  # 记录真实标签所在位置（第i天）\n",
        "\n",
        "# 转换为 NumPy 数组\n",
        "X = np.array(X, dtype=np.float32)\n",
        "y = np.array(y, dtype=np.int32)\n",
        "\n",
        "# === 输出维度和标签分布 ===\n",
        "print(f\"\\n✅ 最终训练样本数：{X.shape[0]}, 每个样本维度：{X.shape[1:]}\")\n",
        "\n",
        "unique, counts = np.unique(y, return_counts=True)\n",
        "print(\"\\n📊 标签分布：\")\n",
        "for u, c in zip(unique, counts):\n",
        "    name = {0: \"观望\", 1: \"买入\", 2: \"卖出\"}.get(u, \"未知\")\n",
        "    print(f\"Label {u}（{name}）→ {c} 条\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LUUtXtpM-FZ0",
        "outputId": "0a1fca3e-9c0d-432d-acb3-0fce6943d7d4"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ 最终训练样本数：2225, 每个样本维度：(30, 6)\n",
            "\n",
            "📊 标签分布：\n",
            "Label 0（观望）→ 1158 条\n",
            "Label 1（买入）→ 694 条\n",
            "Label 2（卖出）→ 373 条\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n📌 最后 10 条训练样本（含目标日的日期、价格与标签）：\")\n",
        "for i in range(-10, 0):\n",
        "    row_idx = indices[i]  # 第 i 个样本的标签在原始 df 中的行号\n",
        "    row = df.loc[row_idx]\n",
        "    label_text = {0: \"观望\", 1: \"买入\", 2: \"卖出\"}.get(row['label'], \"未知\")\n",
        "    print(f\"{len(indices)+i+1:02d} | 日期: {row['Date'].date()} | 价格: {row['Price']:.2f} | 标签: {row['label']}（{label_text}）\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CBOB-HhrIfDX",
        "outputId": "5b871cd9-9823-41bd-a76d-a112a3478621"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📌 最后 10 条训练样本（含目标日的日期、价格与标签）：\n",
            "2216 | 日期: 2025-04-14 | 价格: 0.81 | 标签: 0（观望）\n",
            "2217 | 日期: 2025-04-15 | 价格: 0.81 | 标签: 2（卖出）\n",
            "2218 | 日期: 2025-04-16 | 价格: 0.78 | 标签: 0（观望）\n",
            "2219 | 日期: 2025-04-17 | 价格: 0.78 | 标签: 0（观望）\n",
            "2220 | 日期: 2025-04-21 | 价格: 0.76 | 标签: 1（买入）\n",
            "2221 | 日期: 2025-04-22 | 价格: 0.78 | 标签: 0（观望）\n",
            "2222 | 日期: 2025-04-23 | 价格: 0.81 | 标签: 0（观望）\n",
            "2223 | 日期: 2025-04-24 | 价格: 0.84 | 标签: 0（观望）\n",
            "2224 | 日期: 2025-04-25 | 价格: 0.85 | 标签: 0（观望）\n",
            "2225 | 日期: 2025-04-28 | 价格: 0.85 | 标签: 0（观望）\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lV9E9aPD-gQF"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4toUZjqv-ZGf"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers, models, regularizers\n",
        "\n",
        "def build_cnn_model_3class(input_shape):\n",
        "    input_layer = layers.Input(shape=input_shape)\n",
        "\n",
        "    x = layers.Conv1D(64, 3, padding='same', activation='relu',\n",
        "                      kernel_regularizer=regularizers.l2(0.001))(input_layer)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Conv1D(64, 3, padding='same', activation='relu',\n",
        "                      kernel_regularizer=regularizers.l2(0.001))(x)\n",
        "    x = layers.GlobalMaxPooling1D()(x)\n",
        "\n",
        "    x = layers.Dense(64, activation='relu')(x)\n",
        "    x = layers.Dropout(0.5)(x)\n",
        "\n",
        "    # 三分类输出：0 = 观望, 1 = 买入, 2 = 卖出\n",
        "    output = layers.Dense(3, activation='softmax')(x)\n",
        "\n",
        "    model = models.Model(inputs=input_layer, outputs=output)\n",
        "    model.compile(\n",
        "        optimizer='adam',\n",
        "        loss='sparse_categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "KVPG4o-t8PJI"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers, models, regularizers\n",
        "\n",
        "def build_stronger_cnn_model(input_shape):\n",
        "    input_layer = layers.Input(shape=input_shape)\n",
        "\n",
        "    # --- 多尺度卷积 ---\n",
        "    conv3 = layers.Conv1D(64, 3, padding='same', activation='relu',\n",
        "                          kernel_regularizer=regularizers.l2(0.001))(input_layer)\n",
        "    conv5 = layers.Conv1D(64, 5, padding='same', activation='relu',\n",
        "                          kernel_regularizer=regularizers.l2(0.001))(input_layer)\n",
        "    conv7 = layers.Conv1D(64, 7, padding='same', activation='relu',\n",
        "                          kernel_regularizer=regularizers.l2(0.001))(input_layer)\n",
        "\n",
        "    x = layers.Concatenate()([conv3, conv5, conv7])\n",
        "    x = layers.BatchNormalization()(x)\n",
        "\n",
        "    # --- Global pooling ---\n",
        "    x = layers.GlobalMaxPooling1D()(x)\n",
        "\n",
        "    # --- 全连接 + Dropout ---\n",
        "    x = layers.Dense(128, activation='relu')(x)\n",
        "    x = layers.Dropout(0.4)(x)\n",
        "    x = layers.Dense(64, activation='relu')(x)\n",
        "    x = layers.Dropout(0.3)(x)\n",
        "\n",
        "    # --- 三分类输出 ---\n",
        "    output = layers.Dense(3, activation='softmax')(x)\n",
        "\n",
        "    model = models.Model(inputs=input_layer, outputs=output)\n",
        "    model.compile(\n",
        "        optimizer='adam',\n",
        "        loss='sparse_categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "idcyiYf4DM86"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === 🔥 强化版 CNN 模型（不含 Attention）===\n",
        "\n",
        "from tensorflow.keras import layers, models, regularizers, optimizers\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
        "\n",
        "\n",
        "def build_stronger_cnn_model2(input_shape):\n",
        "    input_layer = layers.Input(shape=input_shape)\n",
        "\n",
        "    # --- 多尺度卷积 ---\n",
        "    conv3 = layers.Conv1D(64, 3, padding='same', activation='relu', kernel_regularizer=regularizers.l2(0.001))(input_layer)\n",
        "    conv5 = layers.Conv1D(64, 5, padding='same', activation='relu', kernel_regularizer=regularizers.l2(0.001))(input_layer)\n",
        "    conv7 = layers.Conv1D(64, 7, padding='same', activation='relu', kernel_regularizer=regularizers.l2(0.001))(input_layer)\n",
        "\n",
        "    x = layers.Concatenate()([conv3, conv5, conv7])\n",
        "    x = layers.BatchNormalization()(x)\n",
        "\n",
        "    # --- 卷积残差块（增强非线性 + 局部感知） ---\n",
        "    res = layers.Conv1D(128, 3, padding='same', activation='relu')(x)\n",
        "    res = layers.BatchNormalization()(res)\n",
        "    res = layers.Conv1D(192, 3, padding='same', activation='relu')(res)\n",
        "    x = layers.Add()([x, res])\n",
        "    x = layers.LayerNormalization()(x)\n",
        "\n",
        "    # --- 池化 + 全连接 ---\n",
        "    x = layers.GlobalMaxPooling1D()(x)\n",
        "    x = layers.Dense(128, activation='relu')(x)\n",
        "    x = layers.Dropout(0.4)(x)\n",
        "    x = layers.Dense(64, activation='relu')(x)\n",
        "    x = layers.Dropout(0.3)(x)\n",
        "\n",
        "    # --- 输出层（三分类）---\n",
        "    output = layers.Dense(3, activation='softmax')(x)\n",
        "\n",
        "    model = Model(inputs=input_layer, outputs=output)\n",
        "    model.compile(\n",
        "        optimizer=optimizers.Adam(learning_rate=1e-4),\n",
        "        loss=SparseCategoricalCrossentropy(),\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "XgzW4jzbDt4M"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_val, y_train, y_val, indices_train, indices_val = train_test_split(\n",
        "    X, y, indices, test_size=0.2, random_state=42, stratify=y\n",
        ")\n"
      ],
      "metadata": {
        "id": "un3vVq_0BqKH"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model = build_cnn_model_3class(input_shape=X.shape[1:])\n",
        "# model = build_stronger_cnn_model(input_shape=X.shape[1:])\n",
        "model = build_stronger_cnn_model2(input_shape=X.shape[1:])\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 826
        },
        "id": "xMqFTRaXBqNM",
        "outputId": "fc5561b1-8570-45b8-8d83-93ba6f25f679"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m6\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │      \u001b[38;5;34m1,216\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │      \u001b[38;5;34m1,984\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_2 (\u001b[38;5;33mConv1D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │      \u001b[38;5;34m2,752\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m192\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ conv1d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ conv1d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
              "│                     │                   │            │ conv1d_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalization │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m192\u001b[0m)   │        \u001b[38;5;34m768\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_3 (\u001b[38;5;33mConv1D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │     \u001b[38;5;34m73,856\u001b[0m │ batch_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │        \u001b[38;5;34m512\u001b[0m │ conv1d_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_4 (\u001b[38;5;33mConv1D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m192\u001b[0m)   │     \u001b[38;5;34m73,920\u001b[0m │ batch_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add (\u001b[38;5;33mAdd\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m192\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│                     │                   │            │ conv1d_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalization │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m192\u001b[0m)   │        \u001b[38;5;34m384\u001b[0m │ add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ global_max_pooling… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m192\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ layer_normalizat… │\n",
              "│ (\u001b[38;5;33mGlobalMaxPooling1…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │     \u001b[38;5;34m24,704\u001b[0m │ global_max_pooli… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m8,256\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │        \u001b[38;5;34m195\u001b[0m │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,216</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,984</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,752</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ conv1d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
              "│                     │                   │            │ conv1d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalization │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │ batch_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv1d_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">73,920</span> │ batch_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│                     │                   │            │ conv1d_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ layer_normalization │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span> │ add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ global_max_pooling… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling1…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">24,704</span> │ global_max_pooli… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">195</span> │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m188,547\u001b[0m (736.51 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">188,547</span> (736.51 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m187,907\u001b[0m (734.01 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">187,907</span> (734.01 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m640\u001b[0m (2.50 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">640</span> (2.50 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "early_stop = EarlyStopping(\n",
        "    monitor='val_loss', patience=6, restore_best_weights=True, verbose=1\n",
        ")\n",
        "\n",
        "lr_scheduler = ReduceLROnPlateau(\n",
        "    monitor='val_loss', factor=0.5, patience=3, verbose=1\n",
        ")\n"
      ],
      "metadata": {
        "id": "3AtK0iUnBqPE"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_val, y_val),\n",
        "    epochs=80,\n",
        "    batch_size=32,\n",
        "    callbacks=[early_stop, lr_scheduler],\n",
        "    verbose=1\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kPBdLXhYBqRg",
        "outputId": "091aa07a-d194-474d-c2ca-c92127ea3c72"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/80\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 134ms/step - accuracy: 0.3645 - loss: 1.7599 - val_accuracy: 0.5371 - val_loss: 1.0561 - learning_rate: 1.0000e-04\n",
            "Epoch 2/80\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4574 - loss: 1.1947 - val_accuracy: 0.4899 - val_loss: 1.0684 - learning_rate: 1.0000e-04\n",
            "Epoch 3/80\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4813 - loss: 1.0911 - val_accuracy: 0.5146 - val_loss: 1.0563 - learning_rate: 1.0000e-04\n",
            "Epoch 4/80\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4682 - loss: 1.0583 - val_accuracy: 0.5551 - val_loss: 1.0215 - learning_rate: 1.0000e-04\n",
            "Epoch 5/80\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5433 - loss: 0.9892 - val_accuracy: 0.5865 - val_loss: 0.9880 - learning_rate: 1.0000e-04\n",
            "Epoch 6/80\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5499 - loss: 0.9550 - val_accuracy: 0.5955 - val_loss: 0.9543 - learning_rate: 1.0000e-04\n",
            "Epoch 7/80\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5518 - loss: 0.9451 - val_accuracy: 0.5798 - val_loss: 0.9361 - learning_rate: 1.0000e-04\n",
            "Epoch 8/80\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5428 - loss: 0.9231 - val_accuracy: 0.5910 - val_loss: 0.8972 - learning_rate: 1.0000e-04\n",
            "Epoch 9/80\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5778 - loss: 0.8871 - val_accuracy: 0.6090 - val_loss: 0.8705 - learning_rate: 1.0000e-04\n",
            "Epoch 10/80\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5905 - loss: 0.8671 - val_accuracy: 0.6360 - val_loss: 0.8366 - learning_rate: 1.0000e-04\n",
            "Epoch 11/80\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6032 - loss: 0.8671 - val_accuracy: 0.6494 - val_loss: 0.8201 - learning_rate: 1.0000e-04\n",
            "Epoch 12/80\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6232 - loss: 0.8303 - val_accuracy: 0.6225 - val_loss: 0.8247 - learning_rate: 1.0000e-04\n",
            "Epoch 13/80\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6465 - loss: 0.7836 - val_accuracy: 0.6112 - val_loss: 0.8343 - learning_rate: 1.0000e-04\n",
            "Epoch 14/80\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6563 - loss: 0.7677 - val_accuracy: 0.6562 - val_loss: 0.7794 - learning_rate: 1.0000e-04\n",
            "Epoch 15/80\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6364 - loss: 0.7832 - val_accuracy: 0.6652 - val_loss: 0.7580 - learning_rate: 1.0000e-04\n",
            "Epoch 16/80\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6523 - loss: 0.7557 - val_accuracy: 0.6652 - val_loss: 0.7545 - learning_rate: 1.0000e-04\n",
            "Epoch 17/80\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6636 - loss: 0.7596 - val_accuracy: 0.6629 - val_loss: 0.7687 - learning_rate: 1.0000e-04\n",
            "Epoch 18/80\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6742 - loss: 0.7223 - val_accuracy: 0.6742 - val_loss: 0.7464 - learning_rate: 1.0000e-04\n",
            "Epoch 19/80\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6775 - loss: 0.7345 - val_accuracy: 0.6674 - val_loss: 0.7490 - learning_rate: 1.0000e-04\n",
            "Epoch 20/80\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6571 - loss: 0.7309 - val_accuracy: 0.6764 - val_loss: 0.7401 - learning_rate: 1.0000e-04\n",
            "Epoch 21/80\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6575 - loss: 0.7164 - val_accuracy: 0.6742 - val_loss: 0.7254 - learning_rate: 1.0000e-04\n",
            "Epoch 22/80\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7174 - loss: 0.6753 - val_accuracy: 0.6787 - val_loss: 0.7433 - learning_rate: 1.0000e-04\n",
            "Epoch 23/80\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6955 - loss: 0.6927 - val_accuracy: 0.6899 - val_loss: 0.7309 - learning_rate: 1.0000e-04\n",
            "Epoch 24/80\n",
            "\u001b[1m55/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6737 - loss: 0.6867\n",
            "Epoch 24: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6743 - loss: 0.6862 - val_accuracy: 0.6697 - val_loss: 0.7297 - learning_rate: 1.0000e-04\n",
            "Epoch 25/80\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7253 - loss: 0.6329 - val_accuracy: 0.7079 - val_loss: 0.7017 - learning_rate: 5.0000e-05\n",
            "Epoch 26/80\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6997 - loss: 0.6473 - val_accuracy: 0.6944 - val_loss: 0.7116 - learning_rate: 5.0000e-05\n",
            "Epoch 27/80\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7330 - loss: 0.6276 - val_accuracy: 0.6966 - val_loss: 0.7140 - learning_rate: 5.0000e-05\n",
            "Epoch 28/80\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7218 - loss: 0.6249 - val_accuracy: 0.7034 - val_loss: 0.6947 - learning_rate: 5.0000e-05\n",
            "Epoch 29/80\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7401 - loss: 0.6016 - val_accuracy: 0.6899 - val_loss: 0.6993 - learning_rate: 5.0000e-05\n",
            "Epoch 30/80\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7356 - loss: 0.5889 - val_accuracy: 0.7169 - val_loss: 0.6819 - learning_rate: 5.0000e-05\n",
            "Epoch 31/80\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7700 - loss: 0.5589 - val_accuracy: 0.6966 - val_loss: 0.6973 - learning_rate: 5.0000e-05\n",
            "Epoch 32/80\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7434 - loss: 0.5888 - val_accuracy: 0.7079 - val_loss: 0.6793 - learning_rate: 5.0000e-05\n",
            "Epoch 33/80\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7642 - loss: 0.5642 - val_accuracy: 0.7146 - val_loss: 0.6694 - learning_rate: 5.0000e-05\n",
            "Epoch 34/80\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7631 - loss: 0.5529 - val_accuracy: 0.7079 - val_loss: 0.6711 - learning_rate: 5.0000e-05\n",
            "Epoch 35/80\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7601 - loss: 0.5526 - val_accuracy: 0.7011 - val_loss: 0.6748 - learning_rate: 5.0000e-05\n",
            "Epoch 36/80\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7751 - loss: 0.5740 - val_accuracy: 0.7034 - val_loss: 0.6667 - learning_rate: 5.0000e-05\n",
            "Epoch 37/80\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7730 - loss: 0.5344 - val_accuracy: 0.7281 - val_loss: 0.6549 - learning_rate: 5.0000e-05\n",
            "Epoch 38/80\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8192 - loss: 0.4765 - val_accuracy: 0.7236 - val_loss: 0.6699 - learning_rate: 5.0000e-05\n",
            "Epoch 39/80\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7670 - loss: 0.5158 - val_accuracy: 0.7371 - val_loss: 0.6618 - learning_rate: 5.0000e-05\n",
            "Epoch 40/80\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7756 - loss: 0.5075 - val_accuracy: 0.7393 - val_loss: 0.6441 - learning_rate: 5.0000e-05\n",
            "Epoch 41/80\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7922 - loss: 0.4900 - val_accuracy: 0.7393 - val_loss: 0.6501 - learning_rate: 5.0000e-05\n",
            "Epoch 42/80\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8196 - loss: 0.4622 - val_accuracy: 0.7483 - val_loss: 0.6147 - learning_rate: 5.0000e-05\n",
            "Epoch 43/80\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8329 - loss: 0.4567 - val_accuracy: 0.7506 - val_loss: 0.6208 - learning_rate: 5.0000e-05\n",
            "Epoch 44/80\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8054 - loss: 0.4637 - val_accuracy: 0.7528 - val_loss: 0.6145 - learning_rate: 5.0000e-05\n",
            "Epoch 45/80\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8131 - loss: 0.4638 - val_accuracy: 0.7551 - val_loss: 0.6156 - learning_rate: 5.0000e-05\n",
            "Epoch 46/80\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8357 - loss: 0.4308 - val_accuracy: 0.7573 - val_loss: 0.6136 - learning_rate: 5.0000e-05\n",
            "Epoch 47/80\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8389 - loss: 0.4041 - val_accuracy: 0.7596 - val_loss: 0.5968 - learning_rate: 5.0000e-05\n",
            "Epoch 48/80\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8554 - loss: 0.3998 - val_accuracy: 0.7618 - val_loss: 0.6103 - learning_rate: 5.0000e-05\n",
            "Epoch 49/80\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8325 - loss: 0.4111 - val_accuracy: 0.7708 - val_loss: 0.5932 - learning_rate: 5.0000e-05\n",
            "Epoch 50/80\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8381 - loss: 0.4054 - val_accuracy: 0.7663 - val_loss: 0.5941 - learning_rate: 5.0000e-05\n",
            "Epoch 51/80\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8445 - loss: 0.3912 - val_accuracy: 0.7573 - val_loss: 0.5710 - learning_rate: 5.0000e-05\n",
            "Epoch 52/80\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8492 - loss: 0.3818 - val_accuracy: 0.7708 - val_loss: 0.5693 - learning_rate: 5.0000e-05\n",
            "Epoch 53/80\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8491 - loss: 0.3767 - val_accuracy: 0.7910 - val_loss: 0.5744 - learning_rate: 5.0000e-05\n",
            "Epoch 54/80\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8429 - loss: 0.3970 - val_accuracy: 0.7798 - val_loss: 0.5833 - learning_rate: 5.0000e-05\n",
            "Epoch 55/80\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8742 - loss: 0.3610 - val_accuracy: 0.7888 - val_loss: 0.5655 - learning_rate: 5.0000e-05\n",
            "Epoch 56/80\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8642 - loss: 0.3564 - val_accuracy: 0.7843 - val_loss: 0.5916 - learning_rate: 5.0000e-05\n",
            "Epoch 57/80\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8848 - loss: 0.3423 - val_accuracy: 0.8000 - val_loss: 0.5561 - learning_rate: 5.0000e-05\n",
            "Epoch 58/80\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8657 - loss: 0.3573 - val_accuracy: 0.7865 - val_loss: 0.5510 - learning_rate: 5.0000e-05\n",
            "Epoch 59/80\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9021 - loss: 0.3114 - val_accuracy: 0.7888 - val_loss: 0.5548 - learning_rate: 5.0000e-05\n",
            "Epoch 60/80\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8806 - loss: 0.3357 - val_accuracy: 0.8045 - val_loss: 0.5468 - learning_rate: 5.0000e-05\n",
            "Epoch 61/80\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8862 - loss: 0.3129 - val_accuracy: 0.7933 - val_loss: 0.5464 - learning_rate: 5.0000e-05\n",
            "Epoch 62/80\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8971 - loss: 0.3036 - val_accuracy: 0.7843 - val_loss: 0.5447 - learning_rate: 5.0000e-05\n",
            "Epoch 63/80\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8727 - loss: 0.3389 - val_accuracy: 0.7910 - val_loss: 0.5614 - learning_rate: 5.0000e-05\n",
            "Epoch 64/80\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8914 - loss: 0.2953 - val_accuracy: 0.7888 - val_loss: 0.5308 - learning_rate: 5.0000e-05\n",
            "Epoch 65/80\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8997 - loss: 0.2890 - val_accuracy: 0.7978 - val_loss: 0.5350 - learning_rate: 5.0000e-05\n",
            "Epoch 66/80\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9036 - loss: 0.2795 - val_accuracy: 0.7910 - val_loss: 0.5714 - learning_rate: 5.0000e-05\n",
            "Epoch 67/80\n",
            "\u001b[1m39/56\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9208 - loss: 0.2522\n",
            "Epoch 67: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9164 - loss: 0.2602 - val_accuracy: 0.7955 - val_loss: 0.5496 - learning_rate: 5.0000e-05\n",
            "Epoch 68/80\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8980 - loss: 0.2867 - val_accuracy: 0.8000 - val_loss: 0.5400 - learning_rate: 2.5000e-05\n",
            "Epoch 69/80\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9357 - loss: 0.2386 - val_accuracy: 0.7888 - val_loss: 0.5222 - learning_rate: 2.5000e-05\n",
            "Epoch 70/80\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9120 - loss: 0.2749 - val_accuracy: 0.8045 - val_loss: 0.5263 - learning_rate: 2.5000e-05\n",
            "Epoch 71/80\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9198 - loss: 0.2637 - val_accuracy: 0.8022 - val_loss: 0.5560 - learning_rate: 2.5000e-05\n",
            "Epoch 72/80\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9075 - loss: 0.2530\n",
            "Epoch 72: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9076 - loss: 0.2530 - val_accuracy: 0.7933 - val_loss: 0.5349 - learning_rate: 2.5000e-05\n",
            "Epoch 73/80\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9176 - loss: 0.2421 - val_accuracy: 0.8022 - val_loss: 0.5469 - learning_rate: 1.2500e-05\n",
            "Epoch 74/80\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9294 - loss: 0.2343 - val_accuracy: 0.7888 - val_loss: 0.5252 - learning_rate: 1.2500e-05\n",
            "Epoch 75/80\n",
            "\u001b[1m40/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9255 - loss: 0.2514\n",
            "Epoch 75: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
            "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9250 - loss: 0.2512 - val_accuracy: 0.8067 - val_loss: 0.5412 - learning_rate: 1.2500e-05\n",
            "Epoch 75: early stopping\n",
            "Restoring model weights from the end of the best epoch: 69.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# === 推理预测 ===\n",
        "pred_probs = model.predict(X_val)\n",
        "pred_labels = np.argmax(pred_probs, axis=1)\n",
        "\n",
        "# === 标签映射（可自定义） ===\n",
        "label_names = {0: \"观望\", 1: \"买入\", 2: \"卖出\"}\n",
        "\n",
        "# === 打印前 N 条预测结果（含时间与价格） ===\n",
        "print(\"\\n📊 测试集预测结果（前20条）：\")\n",
        "for i in range(min(20, len(X_val))):\n",
        "    idx = indices_val[i]  # 找回对应的 df 行\n",
        "    date = df.loc[idx, 'Date']\n",
        "    price = df.loc[idx, 'Price']\n",
        "    actual = y_val[i]\n",
        "    pred = pred_labels[i]\n",
        "    prob = pred_probs[i]\n",
        "\n",
        "    print(f\"{i+1:02d} | 日期: {date.date()} | 价格: {price:.2f} | \"\n",
        "          f\"预测: {label_names[pred]} ({prob[pred]:.2f}) | 实际: {label_names[actual]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JcpwfVRLBqT0",
        "outputId": "2de5200e-a7c4-4792-8af8-4b5115bf293f"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step\n",
            "\n",
            "📊 测试集预测结果（前20条）：\n",
            "01 | 日期: 2023-09-07 | 价格: 0.62 | 预测: 观望 (0.51) | 实际: 观望\n",
            "02 | 日期: 2017-03-10 | 价格: 0.07 | 预测: 观望 (0.72) | 实际: 观望\n",
            "03 | 日期: 2019-10-07 | 价格: 0.20 | 预测: 观望 (0.94) | 实际: 观望\n",
            "04 | 日期: 2023-09-14 | 价格: 0.63 | 预测: 观望 (0.76) | 实际: 观望\n",
            "05 | 日期: 2020-02-19 | 价格: 0.31 | 预测: 观望 (0.93) | 实际: 观望\n",
            "06 | 日期: 2020-08-26 | 价格: 0.43 | 预测: 观望 (0.99) | 实际: 观望\n",
            "07 | 日期: 2018-05-03 | 价格: 0.14 | 预测: 观望 (0.99) | 实际: 观望\n",
            "08 | 日期: 2024-12-12 | 价格: 0.97 | 预测: 买入 (0.82) | 实际: 买入\n",
            "09 | 日期: 2018-09-21 | 价格: 0.19 | 预测: 观望 (0.76) | 实际: 买入\n",
            "10 | 日期: 2021-11-10 | 价格: 0.66 | 预测: 买入 (0.85) | 实际: 买入\n",
            "11 | 日期: 2023-07-11 | 价格: 0.61 | 预测: 观望 (0.95) | 实际: 观望\n",
            "12 | 日期: 2024-01-11 | 价格: 0.70 | 预测: 买入 (0.88) | 实际: 买入\n",
            "13 | 日期: 2018-09-20 | 价格: 0.19 | 预测: 观望 (0.99) | 实际: 观望\n",
            "14 | 日期: 2019-06-07 | 价格: 0.18 | 预测: 买入 (0.73) | 实际: 买入\n",
            "15 | 日期: 2018-04-13 | 价格: 0.14 | 预测: 观望 (0.99) | 实际: 观望\n",
            "16 | 日期: 2017-01-17 | 价格: 0.05 | 预测: 买入 (0.50) | 实际: 观望\n",
            "17 | 日期: 2018-05-30 | 价格: 0.15 | 预测: 卖出 (0.88) | 实际: 卖出\n",
            "18 | 日期: 2024-04-29 | 价格: 0.76 | 预测: 买入 (0.64) | 实际: 买入\n",
            "19 | 日期: 2021-02-23 | 价格: 0.50 | 预测: 卖出 (0.60) | 实际: 卖出\n",
            "20 | 日期: 2022-01-20 | 价格: 0.59 | 预测: 观望 (0.96) | 实际: 观望\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# 模型预测\n",
        "pred_probs = model.predict(X_val)\n",
        "pred_labels = np.argmax(pred_probs, axis=1)\n",
        "\n",
        "# 实际标签\n",
        "actual = y_val\n",
        "\n",
        "# 预测为买入（1）\n",
        "pred_buy_mask = pred_labels == 1\n",
        "buy_correct = np.sum((pred_labels == 1) & (actual == 1))\n",
        "buy_total = np.sum(pred_buy_mask)\n",
        "buy_precision = buy_correct / buy_total if buy_total > 0 else 0\n",
        "\n",
        "# 预测为卖出（2）\n",
        "pred_sell_mask = pred_labels == 2\n",
        "sell_correct = np.sum((pred_labels == 2) & (actual == 2))\n",
        "sell_total = np.sum(pred_sell_mask)\n",
        "sell_precision = sell_correct / sell_total if sell_total > 0 else 0\n",
        "\n",
        "# 输出\n",
        "print(f\"\\n🎯 模型预测精度分析：\")\n",
        "print(f\"🟢 预测为『买入』时的准确率：{buy_precision:.2%}（{buy_correct}/{buy_total}）\")\n",
        "print(f\"🔴 预测为『卖出』时的准确率：{sell_precision:.2%}（{sell_correct}/{sell_total}）\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DEDaf32oCRGq",
        "outputId": "a0423630-4619-4c73-b275-aacfaa5e5e37"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
            "\n",
            "🎯 模型预测精度分析：\n",
            "🟢 预测为『买入』时的准确率：78.32%（112/143）\n",
            "🔴 预测为『卖出』时的准确率：77.14%（54/70）\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"models/stock_cnn_model.h5\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zbc_eYTGFwe_",
        "outputId": "fde2d3cb-eb01-42a1-be83-523c639c05f7"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_latest_from_raw_csv(csv_path, model_path, feature_cols, window=30):\n",
        "    # === 加载模型 ===\n",
        "    model = load_model(model_path)\n",
        "\n",
        "    # === 原始数据处理 ===\n",
        "    df = pd.read_csv(csv_path, parse_dates=['Date'])\n",
        "\n",
        "    for col in ['Price', 'Open', 'High', 'Low']:\n",
        "        df[col] = df[col].astype(str).str.replace(',', '').astype(float)\n",
        "\n",
        "    # 升序排列日期，确保 tail() 拿到的是最新的30天\n",
        "    df = df.sort_values('Date').reset_index(drop=True)\n",
        "\n",
        "    # 添加技术指标（和训练保持一致）\n",
        "    df['MA10'] = df['Price'].rolling(10).mean()\n",
        "    df['RSI'] = compute_rsi(df['Price'])\n",
        "    df['Return5'] = df['Price'].pct_change(5)\n",
        "    df['Volatility5'] = df['Price'].rolling(5).std()\n",
        "    df['Bias_MA10'] = (df['Price'] - df['MA10']) / df['MA10']\n",
        "\n",
        "    df[feature_cols] = df[feature_cols].replace([np.inf, -np.inf], np.nan)\n",
        "\n",
        "    # 取最新 window 天\n",
        "    df_latest = df.tail(window).copy()\n",
        "\n",
        "    if df_latest.shape[0] < window or df_latest[feature_cols].isna().any().any():\n",
        "        print(\"⚠️ 最新30天样本不完整，无法推理\")\n",
        "        return\n",
        "\n",
        "    # 标准化特征\n",
        "    scaler = MinMaxScaler()\n",
        "    df_latest[feature_cols] = scaler.fit_transform(df_latest[feature_cols])\n",
        "\n",
        "    X_latest = np.expand_dims(df_latest[feature_cols].values, axis=0).astype(np.float32)\n",
        "\n",
        "    # === 推理 ===\n",
        "    prob = model.predict(X_latest)[0]\n",
        "    label = np.argmax(prob)\n",
        "    label_map = {0: \"观望\", 1: \"买入\", 2: \"卖出\"}\n",
        "\n",
        "    latest_date = df_latest['Date'].iloc[-1]\n",
        "    latest_price = df_latest['Price'].iloc[-1]\n",
        "\n",
        "    print(f\"\\n📅 最新日期：{latest_date.date()} | 当前价格：{latest_price:.2f}\")\n",
        "    print(f\"🤖 模型预测：{label_map[label]}（概率：{prob[label]:.2%}）\")\n"
      ],
      "metadata": {
        "id": "F35RJEGuFwkm"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_cols = ['Price', 'MA10', 'RSI', 'Return5', 'Volatility5', 'Bias_MA10']\n",
        "\n",
        "predict_latest_from_raw_csv(\n",
        "    csv_path='Nasdaq100Data.csv',\n",
        "    model_path='models/stock_cnn_model.h5',\n",
        "    feature_cols=feature_cols\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hTG3UzwDJBuv",
        "outputId": "713e47c8-1b5a-4eaf-a988-3fd173a92119"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 574ms/step\n",
            "\n",
            "📅 最新日期：2025-05-16 | 当前价格：1.00\n",
            "🤖 模型预测：观望（概率：99.45%）\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_recent_n_days(csv_path, model_path, feature_cols, window=30, n_days=20):\n",
        "    import pandas as pd\n",
        "    import numpy as np\n",
        "    from tensorflow.keras.models import load_model\n",
        "    from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "    def compute_rsi(series, period=14):\n",
        "        delta = series.diff()\n",
        "        gain = delta.clip(lower=0).rolling(window=period).mean()\n",
        "        loss = -delta.clip(upper=0).rolling(window=period).mean()\n",
        "        rs = gain / (loss + 1e-10)\n",
        "        return 100 - (100 / (1 + rs))\n",
        "\n",
        "    # === 加载模型 ===\n",
        "    model = load_model(model_path)\n",
        "    df = pd.read_csv(csv_path, parse_dates=['Date'])\n",
        "\n",
        "    for col in ['Price', 'Open', 'High', 'Low']:\n",
        "        df[col] = df[col].astype(str).str.replace(',', '').astype(float)\n",
        "\n",
        "    df = df.sort_values('Date').reset_index(drop=True)\n",
        "\n",
        "    # 添加指标\n",
        "    df['MA10'] = df['Price'].rolling(10).mean()\n",
        "    df['RSI'] = compute_rsi(df['Price'])\n",
        "    df['Return5'] = df['Price'].pct_change(5)\n",
        "    df['Volatility5'] = df['Price'].rolling(5).std()\n",
        "    df['Bias_MA10'] = (df['Price'] - df['MA10']) / df['MA10']\n",
        "\n",
        "    df[feature_cols] = df[feature_cols].replace([np.inf, -np.inf], np.nan)\n",
        "    df = df.dropna(subset=feature_cols).reset_index(drop=True)\n",
        "\n",
        "    if len(df) < window + n_days:\n",
        "        print(\"❌ 数据不足，无法生成最近 N 天的推理样本\")\n",
        "        return\n",
        "\n",
        "    scaler = MinMaxScaler()\n",
        "    df[feature_cols] = scaler.fit_transform(df[feature_cols])\n",
        "\n",
        "    print(f\"\\n📊 最近 {n_days} 天预测（高置信度提示 🌟）：\")\n",
        "    label_map = {0: \"观望\", 1: \"买入\", 2: \"卖出\"}\n",
        "\n",
        "    for i in range(-n_days, 0):\n",
        "        if i - window < -len(df):\n",
        "            continue\n",
        "        X_seq = df[feature_cols].iloc[i - window:i].values\n",
        "        if X_seq.shape != (window, len(feature_cols)):\n",
        "            continue\n",
        "\n",
        "        X_input = np.expand_dims(X_seq, axis=0).astype(np.float32)\n",
        "        prob = model.predict(X_input, verbose=0)[0]\n",
        "        label = np.argmax(prob)\n",
        "        confidence = prob[label]\n",
        "\n",
        "        date = df['Date'].iloc[i]\n",
        "        price = df['Price'].iloc[i]\n",
        "\n",
        "        # 高置信度标记\n",
        "        marker = \" 🌟 高置信度！\" if confidence > 0.85 else \"\"\n",
        "\n",
        "        print(f\"{date.date()} | 💰{price:.2f} | 预测：{label_map[label]}（概率：{confidence:.2%}）{marker}\")\n"
      ],
      "metadata": {
        "id": "fSFmLZsVJt4n"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_cols = ['Price', 'MA10', 'RSI', 'Return5', 'Volatility5', 'Bias_MA10']\n",
        "predict_recent_n_days(\n",
        "    csv_path='Nasdaq100Data.csv',\n",
        "    model_path='models/stock_cnn_model.h5',\n",
        "    feature_cols=feature_cols,\n",
        "    window=30,\n",
        "    n_days=20\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qS3XuIT3Juon",
        "outputId": "c32958bb-fb2f-4315-c69f-c5266050462e"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 最近 20 天预测（高置信度提示 🌟）：\n",
            "2025-04-21 | 💰0.76 | 预测：观望（概率：94.85%） 🌟 高置信度！\n",
            "2025-04-22 | 💰0.78 | 预测：买入（概率：74.89%）\n",
            "2025-04-23 | 💰0.81 | 预测：买入（概率：95.37%） 🌟 高置信度！\n",
            "2025-04-24 | 💰0.84 | 预测：观望（概率：95.28%） 🌟 高置信度！\n",
            "2025-04-25 | 💰0.85 | 预测：观望（概率：77.01%）\n",
            "2025-04-28 | 💰0.85 | 预测：观望（概率：88.15%） 🌟 高置信度！\n",
            "2025-04-29 | 💰0.85 | 预测：观望（概率：88.66%） 🌟 高置信度！\n",
            "2025-04-30 | 💰0.86 | 预测：观望（概率：95.72%） 🌟 高置信度！\n",
            "2025-05-01 | 💰0.87 | 预测：观望（概率：98.27%） 🌟 高置信度！\n",
            "2025-05-02 | 💰0.88 | 预测：观望（概率：97.21%） 🌟 高置信度！\n",
            "2025-05-05 | 💰0.88 | 预测：观望（概率：96.31%） 🌟 高置信度！\n",
            "2025-05-06 | 💰0.87 | 预测：观望（概率：95.86%） 🌟 高置信度！\n",
            "2025-05-07 | 💰0.87 | 预测：观望（概率：96.42%） 🌟 高置信度！\n",
            "2025-05-08 | 💰0.88 | 预测：观望（概率：98.15%） 🌟 高置信度！\n",
            "2025-05-09 | 💰0.88 | 预测：观望（概率：98.59%） 🌟 高置信度！\n",
            "2025-05-12 | 💰0.93 | 预测：观望（概率：97.30%） 🌟 高置信度！\n",
            "2025-05-13 | 💰0.95 | 预测：观望（概率：95.65%） 🌟 高置信度！\n",
            "2025-05-14 | 💰0.95 | 预测：观望（概率：94.03%） 🌟 高置信度！\n",
            "2025-05-15 | 💰0.95 | 预测：观望（概率：95.17%） 🌟 高置信度！\n",
            "2025-05-16 | 💰0.96 | 预测：观望（概率：95.91%） 🌟 高置信度！\n"
          ]
        }
      ]
    }
  ]
}